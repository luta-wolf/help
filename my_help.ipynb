{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1323645c",
   "metadata": {},
   "source": [
    "# for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5493ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#plot\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#dop\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display\n",
    "from datetime import datetime, timedelta, date, time\n",
    "\n",
    "#prepprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#ML\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#metrics \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# option\n",
    "pd.set_option(\"display.max_columns\", 300)\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "PATH_TRAIN = 'data/train.csv'\n",
    "PATH_TASK = 'data/test.csv'\n",
    "TARGET_COL = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ['time' + str(i) for i in range(1, 11)]\n",
    "\n",
    "train = pd.read_csv(PATH_TRAIN, parse_dates=time, index_col='session_id')\n",
    "task = pd.read_csv(PATH_TASK, parse_dates=time, index_col='session_id')\n",
    "y_train_full = train[[TARGET_COL]]\n",
    "df = pd.concat([train.drop(TARGET_COL, axis=1), task], ignore_index=True)\n",
    "\n",
    "print(train.shape, task.shape)\n",
    "print('-'*50)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92b5a6",
   "metadata": {},
   "source": [
    "# For Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4777dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#plot\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#dop\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from IPython.display import display\n",
    "from datetime import datetime, timedelta, date, time\n",
    "\n",
    "#prepprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#ML\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "#metrics \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# option\n",
    "pd.set_option(\"display.max_columns\", 300)\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "PATH_TRAIN = 'data/train.csv'\n",
    "PATH_TASK = 'data/test.csv'\n",
    "TARGET_COL = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные выделяем 'Y'\n",
    "\n",
    "train = pd.read_csv(PATH_TRAIN)\n",
    "test = pd.read_csv(PATH_TEST)\n",
    "y_train_main = train[TARGET_COL]\n",
    "df = pd.concat([train.drop(TARGET_COL, axis=1), test], ignore_index=True)\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для анализа процеса выполнения в цикле \n",
    "\n",
    "from tqdm import tqdm  \n",
    "from time import sleep \n",
    "for i in tqdm(range(200)):  \n",
    "# Waiting for 0.01 sec before next execution \n",
    "   sleep(.01)\n",
    "\n",
    "    \n",
    "# Если во время выполнения нужен дополнительный вывод, то вместо функции print() \n",
    "# используйте метод tqdm.write() и он предотвратит перенос прогресс бара:    \n",
    ">>> from tqdm import tqdm\n",
    ">>> from time import sleep\n",
    ">>> text = \"\"\n",
    ">>> for char in tqdm([\"a\", \"b\", \"c\", \"d\"], ncols=80):\n",
    "...    sleep(0.25)\n",
    "...    text = text + char\n",
    "...    tqdm.write(text)\n",
    "    \n",
    "\n",
    "# Это для мака\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.gui import tqdm as tqdm_gui\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(0, 100, (100000, 6)))\n",
    "tqdm.pandas(ncols=50)  # can use tqdm_gui, optional kwargs, etc\n",
    "# Now you can use `progress_apply` instead of `apply`\n",
    "df.groupby(0).progress_apply(lambda x: x**2)\n",
    "    \n",
    "    \n",
    "# Now you can just do:\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "# Now you can use `progress_apply` instead of `apply`\n",
    "# and `progress_map` instead of `map`\n",
    "dataset.progress_apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8735590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# читать с файла Pickle\n",
    "with open(r\"data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "list(site_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The inverse dictionary:\n",
    "\n",
    "new_dict = {}\n",
    "for key in site_dict:\n",
    "    new_dict[site_dict[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71372905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывести dataframe красиво в рамке (например в функции)\n",
    "from IPython.display import display\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "df.isna().mean().round(4)*100 - Процентный список пропущенных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка\n",
    "pd.set_option(\"display.max_columns\", 300) - количество выводимых колонок\n",
    "pylab.rcParams['figure.figsize'] = (15, 10) - задать размер графиков\n",
    "\n",
    "# Импорт данных\n",
    "df = pd.read_csv('file') – импорт файла\n",
    "df = pd.read_csv('file', sep=\",\") – импорт файла с разделителем «запятая»\n",
    "\n",
    "# Экспорт данных\n",
    "save_file.to_csv('file.csv', encoding='utf8') – сохранение датафрейма в csv-файл с кодировкой utf8\n",
    "\n",
    "# Вывод на экран\n",
    "df – вывести весь датафрейм\n",
    "df.info – информация о датафрейме\n",
    "df.head(5) – первые пять строчек\n",
    "df.tail(5) – последние пять строчек\n",
    "df.sample(5) – случайные пять строчек\n",
    "df.shape – количество строк и столбцов\n",
    "df.dtypes – типы данных в столбцах\n",
    "df.columns – названия столбцов\n",
    "df['col1'] – значения столбца col1\n",
    "df['col1'][0:20] – срез столбца col1\n",
    "df[['col1', 'col2']] – значения нескольких столбцов\n",
    "df.loc['index_name'] – строки и/или столбцы по нечисловому значению индекса\n",
    "df.iloc[0] – строки и/или столбцы по числовому индексу\n",
    "df.iloc[2,4] – значение ячейки в третьей строчке и пятом столбце\n",
    "\n",
    "# Копирование датафрейма\n",
    "df2 = df1.copy – создает глубокую копию датафрейма\n",
    "\n",
    "# Добавление строчек и столбцов\n",
    "new_row = {'col1': 'Hello', 'col2': 123}\n",
    "df = df.append(new_row, ignore_index=True) – добавляет в конец df строчку new_row\n",
    "df.loc[2] = ['Hello', 123] – добвляет строчку на третье место с начала фрейма\n",
    "df['new_column'] = 'abcd' – создает столбец со значениями abcd\n",
    "\n",
    "# Удаление строчек и столбцов\n",
    "df.drop(26954, 0) – удаляет строчку номер 26954\n",
    "df.drop('col', 1) – удаляет столбец col\n",
    "\n",
    "# Переименование столбцов\n",
    "df.rename(columns={'col1': 'new_col1'}) – меняет имя столбца с col1 на new_col1\n",
    "\n",
    "# Изменение значения в ячейке\n",
    "df['col'] = df['col'].replace(to_replace=2020, value=2021) – меняем все значения с 2020 на 2021\n",
    "df['col'] = df['col'].mask(df['col'] == 2001, 2021) – аналогично, меняем все значения с 2020 на 2021\n",
    "\n",
    "# Сортировка\n",
    "df.sort_values('col', ascending=False) – сортировка в обратном алфавитном порядке\n",
    "df.sort_values(['col1', 'col2']) – сортировка по двум столбцам. col1 – в приоритете, так как первый\n",
    "\n",
    "# Изменение типов\n",
    "df['col'] = df['col'].astype(str) – меняет тип переменных на str\n",
    "df['col'] = df['col'].astype(float) – на float\n",
    "df['col'] = df['col'].astype('int32') – на int32\n",
    "df['col'] = df['col'].astype('int64') – на int64\n",
    "df['col'] = pd.to_numeric(df['col1']) –  на int64\n",
    "\n",
    "# Удаление и замена NaN-значений\n",
    "df.dropna() – удаляет строчки с отсутствующими значениями\n",
    "df.dropna(axis=1) – удаляет столбцы с отсутствующими значениями\n",
    "df.fillna('abcd') – меняет NaN на abcd\n",
    "\n",
    "# Удаление лишних пробелов\n",
    "df['col'] = df['col'].map(str.strip) – удаляет пробелы слева и справа\n",
    "\n",
    "# Фильтрация и поиск\n",
    "df['col'].str.startswith('a') – ищет совпадение по первому символу строки, не поддерживает regex\n",
    "df['col'].str.endswith('a') – ищет совпадение по последнему символу строки, не поддерживает regex\n",
    "df['col'].str.match('a') – определяет, начинается ли каждая строка с шаблона\n",
    "df['col'].str.findall('a') – возвращает совпадения шаблонов\n",
    "df['col'].str.contains('a') – в результате поиска возвращает булево значение\n",
    "df['col'].str.extractall('a') – вернет столбец с поисковым шаблоном\n",
    "df.loc[df['col'].isin(['a', 'b'])] – ищет совпадения в столбцах\n",
    "\n",
    "# Статистические данные\n",
    "df.describe() – статистическая сводка по численным значениями\n",
    "\n",
    "# Подсчет количества повторов\n",
    "df['col'].value_counts() – показывает сколько раз значения повторяются в столбце\n",
    "df['col_result'] = df.groupby('col')['col'].transform('count') – создает столбец с количеством повторов значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67acaaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка дат\n",
    "df['col'] = pd.to_datetime(df['col']) – меняет тип на datetime64[ns]\n",
    "df['col'].dt.day – вытаскивает из столбца col только значение дня\n",
    "df['col'].dt.month – только месяц\n",
    "df['col'].dt.year – только год"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e64cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение датафреймов\n",
    "df1 = pd.concat([df1, df2], axis=0) – к df1 добавляем строчки df2\n",
    "df1 = pd.concat([df1, df2], axis=1) – к df1 добавляем столбцы df2\n",
    "df1 = df1.append(df2) – к df1 добавляем строчки df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ecb744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Когда много признаков и нужно отобрать с помощью регулярных выражениях\n",
    "\n",
    "[x for x in df.columns if re.match(r'metro_', x) != None] # Ищет в начале строки\n",
    "# пример вывода: ['metro_min_avto', 'metro_km_avto', 'metro_min_walk', 'metro_km_walk']\n",
    "\n",
    "# Основные функции модуля re:\n",
    "\n",
    "# match - ищет последовательность в начале строки\n",
    "# search - ищет первое совпадение с шаблоном\n",
    "# findall - ищет все совпадения с шаблоном. Возвращает результирующие строки в виде списка\n",
    "# finditer - ищет все совпадения с шаблоном. Возвращает итератор\n",
    "# compile - компилирует регулярное выражение. К этому объекту затем можно применять все перечисленные функции\n",
    "# fullmatch - вся строка должна соответствовать описанному регулярному выражению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb1cea",
   "metadata": {},
   "source": [
    "# PARAMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb61355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM tuning\n",
    "\n",
    "params  =  {'num_leaves':  np.arange(1, 100001, step=5000),\n",
    "            'max_depth': np.arange(10, 30, step=2),\n",
    "            'learning_rate': [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "            'n_estimators': np.arange(500, 1000, step=100),\n",
    "            'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'feature_fraction': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'bagging_fraction': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "            'bagging_seed': np.arange(1, 20, step=1),\n",
    "            'lambda_l1': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "            'lambda_l2': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "            'min_child_samples': np.arange(5, 105, step=25),\n",
    "            'min_split_gain': [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "            }\n",
    "\n",
    "params  =  {'num_leaves': np.arange(2000, 3200, step=100),\n",
    "            'max_depth': [16, 18, 20, 22, 24],\n",
    "            'learning_rate': [0.001, 0.01, 0.1],\n",
    "            'n_estimators': np.arange(1000, 2500, step=100),\n",
    "            'subsample': [0.3, 0.35, 0.4],\n",
    "            'feature_fraction': [0.2, 0.25, 0.3],\n",
    "            'bagging_fraction': [0.2, 0.3, 0.4, 0,5],\n",
    "            'bagging_seed': [10, 12, 14, 16, 18],\n",
    "            'lambda_l1': [0.2, 0.3, 0.4],\n",
    "            'lambda_l2': [0.1, 0.2, 0.3],\n",
    "            'min_child_samples': [20, 24, 28, 32, 36],\n",
    "            'min_split_gain': [0.00001, 0.0001, 0.001, 0.01],\n",
    "            'n_jobs':[-1],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost tuning\n",
    "\n",
    "params  =  {'subsample': [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1],\n",
    "            'learning_rate': [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "            'max_depth': [0, 4, 5, 6, 7, 8, 10, 12, 14, 16, 18, 20, 22, 25, 28, 30],\n",
    "            'gamma': [0, 1, 2, 3, 5, 10, 20, 50, 200],\n",
    "            'n_estimators': np.arange(500, 5000, step=500),\n",
    "            'colsample_bytree': [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1],\n",
    "            'colsample_bylevel': [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1],\n",
    "            'colsample_bynode': [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1],\n",
    "            'min_child_weight': [1, 2, 3, 5, 10, 20],\n",
    "            'seed': np.arange(5, 50, step=5),\n",
    "            'reg_alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "            }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingRegressor tuning\n",
    "\n",
    "params   = {'n_estimators': np.arange(100, 10000, step=100),\n",
    "            'learning_rate': [.01, .05, 0.1, .2, .3, .4, .5], \n",
    "            'max_depth': np.arange(1, 20, step=1),         \n",
    "            'max_features': ['sqrt'],                                  \n",
    "            'min_samples_leaf': [5, 10, 15, 20, 25],                  \n",
    "            'min_samples_split': [5, 10, 15, 20, 25],                  \n",
    "            'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "            'criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsRegressor tuning\n",
    "\n",
    "params  = { 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'leaf_size': [2, 5, 10, 15, 20, 30, 40, 50],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'metric': ['euclidean', 'manhattan'],\n",
    "            'n_neighbors': [2, 3, 4, 5, 6, 8, 10, 12, 14, 16],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor tuning\n",
    "\n",
    "params = {'bootstrap': [True, False],\n",
    "         'max_depth': [10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_leaf': [1, 2, 3, 4, 5, 7, 9, 11, 13, 15],\n",
    "         'min_samples_split': [2, 3, 4, 5, 7, 8, 10],\n",
    "         'n_estimators': [200, 400, 800, 1200, 1600, 2000],\n",
    "         'max_leaf_nodes' : [, 2, 3, 4, 5, 7, 9, 11, 13, 15],\n",
    "         'max_samples' : [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1],\n",
    "         'n_jobs':[-1],\n",
    "         'oob_score':[True]\n",
    "         } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e21373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostRegressor tuning\n",
    "\n",
    "# params = {'learning_rate': [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "#           'depth': [6, 7, 8, 10, 12, 14, 16, 18, 20, 22, 24],\n",
    "#           'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "#           'rsm' : [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1],\n",
    "#           'silent' : [True]\n",
    "#           }\n",
    "\n",
    "# params = {'n_estimators' : [300, 500, 800],\n",
    "#           'max_depth': [2, 3, 5],\n",
    "#           'l2_leaf_reg': [3, 5, 8],\n",
    "#           'silent' : [True]\n",
    "#          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6c77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
